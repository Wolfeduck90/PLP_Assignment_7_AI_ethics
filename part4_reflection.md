# Part 4: Ethical Reflection (5%)

## ü™û Personal Project Reflection

As part of my commitment to ethical AI design, I reflected on a future project: creating a conversational agent to support mental health and emotional resilience.

### ‚öñÔ∏è Principles Applied

- **Autonomy:** The agent will request informed consent before storing or analyzing personal insights. Data collection will be opt-in and clearly communicated to users.
  
- **Non-maleficence:** Emotional safeguards will be embedded. The bot will avoid making medical claims, and in moments of user distress, redirect to licensed professionals or emergency services.

- **Justice:** Dataset curation will include diverse expressions across cultures, genders, and emotional experiences, minimizing exclusion or bias in conversational output.

- **Transparency:** A detailed user-facing explainer will describe how the AI functions, its data sources, and why certain responses are given ‚Äî promoting understanding and trust.

- **Sustainability:** Model training will be optimized for low-energy consumption, and deployment will favor infrastructure powered by renewable sources where possible.

### üí° Final Thought

Ethics in AI is more than a checkpoint ‚Äî it‚Äôs a continuous conversation. Every design choice is an opportunity to show empathy, inclusivity, and foresight. My goal is to build tools that not only function but care.
